{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the necessary modules\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV # For model selection\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_location):\n",
    "    f_loc = file_location\n",
    "    h_claims = pd.read_csv(f_loc)\n",
    "    return (h_claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>DATA PROCESSING<b/>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "returns a dataframe with only the chosen columns and all the types int64 changed to float64\n",
    "\"\"\"\n",
    "def prep_data(file_data):\n",
    "    \n",
    "    hc_relcols = file_data.drop(['Row_ID', 'Household_ID'], axis=1) # these rows are not relevant to the prediction model\n",
    "    \n",
    "    hc_relcols = hc_relcols.drop(['Cat2','Cat4','Cat5','Cat7','OrdCat'], axis=1) # these columns have been removed to reduce the vector space. These specifically were chosen because they have alot of missing data \n",
    "    \n",
    "    hc_relcols = hc_relcols.drop(['Var2','Var3','Var4','Var8','NVVar2', 'NVVar3', 'NVVar4'], axis=1) # these columns were dropped to reduce the vector space and becasue they were not relevant to the prediction\n",
    "    \n",
    "    for col in ['Vehicle', 'Calendar_Year', 'Model_Year']:  #changing all the ints to floats\n",
    "        hc_relcols[col] = hc_relcols[col].astype('float64')\n",
    "    \n",
    "    hc_relcols.dropna() # drop the rows with missing data\n",
    "    \n",
    "    all_cols = list(hc_relcols.columns) #finding the mode of each column to replace missing values in the data\n",
    "    mode_list = []\n",
    "\n",
    "    for i in range(len(all_cols)):\n",
    "        each_col = str(all_cols[i])\n",
    "        mode_list.append(hc_relcols[each_col].mode()[0])\n",
    "\n",
    "    for i in range(hc_relcols.shape[1]): #replace '?' with mode\n",
    "        if(type(hc_relcols.iloc[1,i]) is str):\n",
    "            for c in range(hc_relcols.shape[0]):\n",
    "                if ((hc_relcols.iloc[c,i]) == '?'):\n",
    "                    hc_relcols.iloc[c,i] = mode_list[i]\n",
    "\n",
    "    return (hc_relcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_cols():\n",
    "\n",
    "    ftrs_cat_slctd = ['Blind_Make','Blind_Model','Blind_Submodel','Cat1','Cat3','Cat6','Cat8','Cat9','Cat10','NVCat',]\n",
    "\n",
    "    ftrs_flt_slctd = ['Vehicle','Calendar_Year','Model_Year','Var1','Var5','Var6','Var7','NVVar1']\n",
    "\n",
    "\n",
    "    full_transform = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), ftrs_flt_slctd),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown='ignore'), ftrs_cat_slctd),\n",
    "    ])\n",
    "    \n",
    "    return (full_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation with standardization\n",
    "def ns_trans_cols():\n",
    "    \n",
    "    ftrs_cat_slctd = ['Blind_Make','Blind_Model','Blind_Submodel','Cat1','Cat3','Cat6','Cat8','Cat9','Cat10','NVCat',]\n",
    "\n",
    "    full_transform = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown='ignore'), ftrs_cat_slctd),\n",
    "    ])\n",
    "    return (full_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data contained more zero labels than none zero labels. To prevent incorrect training an equal number of zero and non-zero \n",
    "data points were selected for training\n",
    "\"\"\"\n",
    "\n",
    "def bal_set(dt_set):\n",
    "    hc_train_set = dt_set\n",
    "   \n",
    "    subset_zeros = hc_train_set[hc_train_set.Claim_Amount == 0]  #choose a equal number of zero and none zero data points\n",
    "\n",
    "    subset_not_zeros = hc_train_set[hc_train_set.Claim_Amount > 0]\n",
    "    \n",
    "    equal_subset_zeros = subset_zeros[0:7662]\n",
    "\n",
    "    balanced_hc_train_set = pd.concat([equal_subset_zeros, subset_not_zeros], ignore_index=True)\n",
    "    \n",
    "    return (balanced_hc_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PERFORMANCE USING A SINGLE MODEL<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split the train data into train and validation\n",
    "\"\"\"\n",
    "def prt_set(dt_set):\n",
    "    balanced_hc_train_set = dt_set\n",
    "    \n",
    "    \n",
    "    hc_subsettrain_set, hc_subsetval_set = train_test_split(balanced_hc_train_set, test_size=0.15, random_state=42)\n",
    "    \n",
    "    hc_subsettrain_set_ftrs = hc_subsettrain_set.drop('Claim_Amount', axis=1) \n",
    "    hc_subsettrain_set_lbls = hc_subsettrain_set['Claim_Amount']\n",
    "\n",
    "    hc_subsetval_set_ftrs = hc_subsetval_set.drop('Claim_Amount', axis=1)\n",
    "    hc_subsetval_set_lbls = hc_subsetval_set['Claim_Amount']\n",
    "    \n",
    "    full_transform = trans_cols()\n",
    "    \n",
    "    hc_train_set_fts_trfmd = full_transform.fit_transform(hc_subsettrain_set_ftrs)\n",
    "    hc_val_set_fts_trfmd = full_transform.transform(hc_subsetval_set_ftrs)\n",
    "        \n",
    "    return (hc_train_set_fts_trfmd, hc_subsettrain_set_lbls, hc_val_set_fts_trfmd, hc_subsetval_set_lbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>a) Linear regression<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performs a gradient search for determining hyprparameters and then carries out a linear regression\n",
    "\"\"\"\n",
    "def gr_search_lin(train_ftrs, train_lbls, val_ftrs, val_lbls):\n",
    "    tf = train_ftrs\n",
    "    tl = train_lbls\n",
    "    vf = val_ftrs\n",
    "    vl = val_lbls\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lin_reg = LinearRegression()\n",
    "\n",
    "    par_fit_intercept = np.array([True, False])\n",
    "    param_normalize = np.array([True, False])\n",
    "    param_copy = np.array([True, False])\n",
    "    param_njobs = [3, 6, 9, 12]\n",
    "    \n",
    "    param_grid = dict(fit_intercept=par_fit_intercept, normalize=param_normalize, copy_X=param_copy, n_jobs=param_njobs)\n",
    "    cv = ShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "    \n",
    "    grid = GridSearchCV(lin_reg, param_grid=param_grid, cv=cv,)\n",
    "    grid.fit(train_ftrs, train_lbls)\n",
    "    \n",
    "    params = grid.best_params_\n",
    "    print(params)\n",
    "\n",
    "    lin_reg = LinearRegression(params)\n",
    "    lin_reg.fit(tf, tl)\n",
    "    \n",
    "    hc_predictions_linear = lin_reg.predict(vf)\n",
    "\n",
    "    error_mod_lin = np.sqrt(mean_squared_error(vl, hc_predictions_linear))\n",
    "    error_mod_lin\n",
    "    \n",
    "    return (grid.best_params_, error_mod_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Obtain hyperparameters for Linear Regression\n",
    "\"\"\"\n",
    "def hp_linear_regression(test_set):\n",
    "    chosen_data = prep_data(test_set)\n",
    "    balanced_data_set = bal_set(chosen_data)\n",
    "    td,tl,vd,vl = prt_set(balanced_data_set)\n",
    "    lin_reg = gr_search_lin(td,tl,vd,vl)\n",
    "    \n",
    "    return (lin_reg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = get_data('./train.csv')\n",
    "l_pred = hp_linear_regression(test_set)\n",
    "\n",
    "print(l_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>b) Ridge regression <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performs Gradient Search and then carries out a Ridge regression prediction\n",
    "\"\"\"\n",
    "def gr_search_ridge(train_ftrs, train_lbls, val_ftrs, val_lbls):\n",
    "\n",
    "    tf = train_ftrs\n",
    "    tl = train_lbls\n",
    "    vf = val_ftrs\n",
    "    vl = val_lbls\n",
    "    \n",
    "    rig_reg = Ridge()\n",
    "\n",
    "    param_alpha = ([1,0.1,0.01])\n",
    "    par_fit_intercept = np.array([True, False])\n",
    "    param_normalize = np.array([True, False])\n",
    "    param_copy = np.array([True, False])\n",
    "    param_maxiter = [1000, 2000]\n",
    "    param_tol = [0.001, 0.005]\n",
    "    param_solver = ['sag']\n",
    "    param_rstate = [None, 3, 5]\n",
    "    \n",
    "    param_grid = dict(alpha = param_alpha, fit_intercept=par_fit_intercept, normalize=param_normalize, copy_X=param_copy, max_iter=param_maxiter, tol=param_tol, solver=param_solver, random_state=param_rstate)\n",
    "    cv = ShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "    \n",
    "    grid = GridSearchCV(rig_reg, param_grid=param_grid, cv=cv,)\n",
    "    grid.fit(train_ftrs, train_lbls)\n",
    "    \n",
    "    params = grid.best_params_\n",
    "\n",
    "    rig_reg = Ridge()\n",
    "    rig_reg.fit(tf, tl)\n",
    "    \n",
    "    hc_predictions_ridge = rig_reg.predict(vf)\n",
    "\n",
    "    error_mod_lin = np.sqrt(mean_squared_error(vl, hc_predictions_ridge))\n",
    "    error_mod_lin\n",
    "    \n",
    "    return (grid.best_params_, error_mod_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_ridge_regression(test_set):\n",
    "    chosen_data = prep_data(test_set)\n",
    "    balanced_data_set = bal_set(chosen_data)\n",
    "    td,tl,vd,vl = prt_set(balanced_data_set)\n",
    "    ridge_reg = gr_search_ridge(td,tl,vd,vl)\n",
    "    \n",
    "    return(ridge_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = get_data('./train.csv')\n",
    "\n",
    "ridge_prdcts = hp_ridge_regression(test_set)\n",
    "print(ridge_prdcts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>c) Random forests for regression<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performs a Gradient Search for hyper parematers and then performs a Random Forest Regression prediction\n",
    "\"\"\"\n",
    "def gr_search_rf(train_ftrs, train_lbls, val_ftrs, val_lbls):\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.model_selection import GridSearchCV # For model selection\n",
    "\n",
    "    tf = train_ftrs\n",
    "    tl = train_lbls\n",
    "    vf = val_ftrs\n",
    "    vl = val_lbls\n",
    "\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    rtree_reg = RandomForestRegressor()\n",
    "\n",
    "    p_nest = np.array([10, 100]) \n",
    "    p_crit = criterion=['mse', 'mae'] \n",
    "    p_mdepth = [1, 5]\n",
    "    p_msamples =[2, 4] \n",
    "    p_msleaf = [1, 2] \n",
    "    p_mwfleaf = [0.0, 0.5]\n",
    "    p_mfeat = ['auto', 'sqrt'] \n",
    "    p_mlnodes = [2, 4] \n",
    "    p_midec = [0.0, 0.5] \n",
    "    p_misplit = [1, 3] \n",
    "    p_bootstrap = [True, False] \n",
    "    p_oscore= [False, True] \n",
    "    p_njobs= [2, 5] \n",
    "    p_rstate = [5, 10] \n",
    "    p_verbose= [0, 1, 5] \n",
    "    p_wstart = [False, True] \n",
    "    p_calpha = [0.0] \n",
    "    p_msamples = [2, 5]\n",
    "    \n",
    "    param_grid = dict(n_estimators=p_nest, criterion=p_crit, max_depth=p_mdepth, min_samples_split=p_msamples, \\\n",
    "                      min_samples_leaf=p_msleaf, min_weight_fraction_leaf=p_mwfleaf, max_features=p_mfeat, \\\n",
    "                      max_leaf_nodes=p_mlnodes, min_impurity_decrease=p_midec, min_impurity_split=p_misplit, \\\n",
    "                      bootstrap=p_bootstrap, oob_score=p_oscore, n_jobs=p_njobs, random_state=p_rstate, \\\n",
    "                      verbose=p_verbose, warm_start=p_wstart)\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "    \n",
    "    grid = GridSearchCV(rtree_reg, param_grid=param_grid, cv=cv,)\n",
    "    grid.fit(train_ftrs, train_lbls)\n",
    "    \n",
    "    params = grid.best_params_\n",
    "\n",
    "    rtree_reg = RandomForestRegressor(params)\n",
    "    rtree_reg.fit(tf, tl)\n",
    "    \n",
    "    hc_predictions_rtree = rtree_reg.predict(vf)\n",
    "\n",
    "    error_mod_lin = np.sqrt(mean_squared_error(vl, hc_predictions_rtree))\n",
    "    error_mod_lin\n",
    "    \n",
    "    return (grid.best_params_, error_mod_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_random_forests(test_set):\n",
    "    chosen_data = prep_data(test_set)\n",
    "    balanced_data_set = bal_set(chosen_data)\n",
    "    td,tl,vd,vl = prt_set(balanced_data_set)\n",
    "    \n",
    "    td_s = td[0:50] #subset of data to save on time for gradeint search\n",
    "    tl_s = tl[0:50]\n",
    "    vd_s = vd[0:25]\n",
    "    vl_s = vl[0:25]\n",
    "    \n",
    "    rtree_reg = gr_search_rf(td_s,tl_s,vd_s,vl_s)\n",
    "    \n",
    "    return(rtree_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without gradient boosting\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "chosen_data = prep_data(test_set)\n",
    "balanced_data_set = bal_set(chosen_data)\n",
    "td,tl,vd,vl = prt_set(balanced_data_set)\n",
    "\n",
    "rtree_reg = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None, max_features='auto', \\\n",
    "                                    max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\\\n",
    "                                    min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=20,\\\n",
    "                                    n_jobs=None,oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "rtree_reg.fit(td, tl ,sample_weight=None)\n",
    "    \n",
    "hc_predictions_rtree = rtree_reg.predict(vd)\n",
    "\n",
    "error_mod_lin = np.sqrt(mean_squared_error(vl, hc_predictions_rtree))\n",
    "error_mod_lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>d) Gradient tree boosting for regression <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performs a Gradient Search for hyper parematers and then performs a Gradient Tree Boosting prediction\n",
    "\"\"\"\n",
    "def gr_search_gtb(train_ftrs, train_lbls, val_ftrs, val_lbls):\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.model_selection import GridSearchCV # For model selection\n",
    "\n",
    "    tf = train_ftrs\n",
    "    tl = train_lbls\n",
    "    vf = val_ftrs\n",
    "    vl = val_lbls\n",
    "\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    gradtree_reg = GradientBoostingRegressor()\n",
    "\n",
    "    p_lrate = [0.1, 0.2] \n",
    "    p_nest= [200, 500] \n",
    "    p_ssa = [0.5, 1] \n",
    "    p_crit=['friedman_mse', 'mse', 'mae'] \n",
    "    p_mss=[2, 5] \n",
    "    p_msl = [2, 5] \n",
    "    p_mwfl = [0.25, 0.5] \n",
    "    p_md = [3, 10] \n",
    "    p_mid = [0.5, 1.0] \n",
    "    p_init = [None, 'zero'] \n",
    "    p_rs = [2, 5] \n",
    "    p_mf = ['auto', 'sqrt'] \n",
    "    p_ver = [0, 2, 5]\n",
    "    p_mln = [5, 10] \n",
    "    p_ws = [False, True] \n",
    "    p_vf = [0.1, 0.2, 0.5] \n",
    "    p_nnc = [1, 5] \n",
    "    p_tol = [0.0001] \n",
    "    \n",
    "    param_grid = dict(learning_rate=p_lrate, n_estimators=p_nest, subsample=p_ssa, criterion=p_crit,\\\n",
    "                      min_samples_split=p_mss, min_samples_leaf=p_msl, min_weight_fraction_leaf=p_mwfl,\\\n",
    "                      max_depth=p_md, min_impurity_decrease=p_mid, init=p_init, random_state=p_rs,\\\n",
    "                      max_features=p_mf, verbose=p_ver, max_leaf_nodes=p_mln, warm_start=p_ws)\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "    \n",
    "    grid = GridSearchCV(gradtree_reg, param_grid=param_grid, cv=cv,)\n",
    "    grid.fit(train_ftrs, train_lbls)\n",
    "    \n",
    "    params = grid.best_params_\n",
    "    \n",
    "    gradtree_reg = GradientBoostingRegressor(params)\n",
    "    gradtree_reg.fit(tf, tl)\n",
    "    \n",
    "    hc_predictions_gradtree = rig_reg.predict(vf)\n",
    "\n",
    "    error_mod_lin = np.sqrt(mean_squared_error(vl, hc_predictions_gradtree))\n",
    "    error_mod_lin\n",
    "    \n",
    "    return (grid.best_params_, error_mod_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_gradient_tree(test_set):\n",
    "    chosen_data = prep_data(test_set)\n",
    "    balanced_data_set = bal_set(chosen_data)\n",
    "    td,tl,vd,vl = prt_set(balanced_data_set)\n",
    "    \n",
    "    td_s = td[0:10] #subset of data to save on time for gradeint search\n",
    "    tl_s = tl[0:10]\n",
    "    vd_s = vd[0:2]\n",
    "    vl_s = vl[0:2]\n",
    "\n",
    "    gtree_reg = gr_search_gtb(td_s,tl_s,vd_s,vl_s)\n",
    "    \n",
    "    return(rtree_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "chosen_data = prep_data(test_set)\n",
    "balanced_data_set = bal_set(chosen_data)\n",
    "td,tl,vd,vl = prt_set(balanced_data_set)\n",
    "\n",
    "gradtree_reg = GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None, learning_rate=0.1, loss='ls', max_depth=3, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_iter_no_change=None, presort='auto', random_state=0, subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "gradtree_reg.fit(td, tl)\n",
    "    \n",
    "hc_predictions_gradtree = gradtree_reg.predict(vd)\n",
    "\n",
    "error_mod_lin = np.sqrt(mean_squared_error(vl, hc_predictions_gradtree))\n",
    "error_mod_lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PERFORMANCE USING A COMBINATION OF TWO MODELS<b/>"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build a prediction model based on two separate models in tandem (one after the other, see Figure 1). Once again, be careful about the preprocessing step 1. For this step, use the same training and validation sets from step 2.\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper function used when working with two models\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def choose_model(name, train_data, train_labels, val_data):\n",
    "    pred_model = name\n",
    "    td = train_data\n",
    "    tl = train_labels\n",
    "    vd = val_data\n",
    "    \n",
    "    if(pred_model == 'Linear'):\n",
    "        lin_reg = LinearRegression(fit_intercept = False, normalize = True, copy_X = True, n_jobs = 3 )\n",
    "        lin_reg.fit(td, tl)\n",
    "        \n",
    "        predictions = lin_reg.predict(vd)\n",
    "        \n",
    "    elif(pred_model == 'Ridge'):\n",
    "        rig_reg = Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, normalize=False, random_state=None, solver='auto', tol=0.001)\n",
    "        rig_reg.fit(td, tl)\n",
    "        \n",
    "        predictions = rig_reg.predict(vd)\n",
    "\n",
    "    elif(pred_model == 'Forests'):\n",
    "        rtree_reg = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None, max_features='auto', \\\n",
    "                                    max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\\\n",
    "                                    min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=20,\\\n",
    "                                    n_jobs=None,oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "        rtree_reg.fit(td, tl ,sample_weight=None)\n",
    "        \n",
    "        predictions = rtree_reg.predict(vd)\n",
    "\n",
    "    elif(pred_model == 'Gradient'):\n",
    "        gradtree_reg = GradientBoostingRegressor( alpha=0.9, criterion='friedman_mse', init=None, learning_rate=0.1, loss='ls', max_depth=3, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_iter_no_change=None, presort='auto', random_state=0, subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "        gradtree_reg.fit(td, tl)\n",
    "        \n",
    "        predictions = gradtree_reg.predict(vd)\n",
    "\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Carry out prediction using two models\n",
    "\"\"\"\n",
    "\n",
    "def comb_models(datafr, model1, model2):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "\n",
    "    d_set = datafr\n",
    "    m1 = model1\n",
    "    m2 = model2\n",
    "    \n",
    "    row_in = []\n",
    "    for i in range(d_set.shape[0]):\n",
    "        row_in.append(i+1)\n",
    "        \n",
    "    bn_values = []\n",
    "    for i in range(d_set.shape[0]):\n",
    "        if (d_set.iloc[i,(d_set.shape[1]-1)] == 0):\n",
    "            bn_values.append(0)\n",
    "        else:\n",
    "            bn_values.append(1)\n",
    "\n",
    "\n",
    "    #insert these two lists into the dataframe\n",
    "    d_set.insert(d_set.shape[1], 'Row_ind', row_in)\n",
    "    d_set.insert(d_set.shape[1], 'Bn_val', bn_values)\n",
    "    \n",
    "    \n",
    "    #Split the train data into train and validation\n",
    "    comb_train_set, comb_val_set = train_test_split(d_set, test_size=0.15, random_state=42)\n",
    "\n",
    "    ##for first model\n",
    "    first_model_ftrs = comb_train_set.drop(['Claim_Amount', 'Row_ind', 'Bn_val'],  axis=1) \n",
    "    first_model_lbls = comb_train_set['Bn_val']\n",
    "\n",
    "    first_model_val_ftrs = comb_val_set.drop(['Claim_Amount', 'Row_ind', 'Bn_val'], axis=1) \n",
    "    first_model_val_lbls = comb_val_set['Bn_val']\n",
    "\n",
    "    ##for second model\n",
    "    second_model_ftrs = comb_train_set[comb_train_set['Bn_val'] == 1]\n",
    "    second_model_lbls = second_model_ftrs['Claim_Amount']\n",
    "    second_model_ftrs_drop = second_model_ftrs.drop(['Claim_Amount', 'Row_ind', 'Bn_val'],  axis=1) \n",
    "\n",
    "    ##filtered below\n",
    "    second_model_val_ftrs = comb_val_set.drop(['Bn_val'], axis=1) \n",
    "\n",
    "    #transformations\n",
    "    #transforming the train feature vecotrs\n",
    "    full_transform = trans_cols()\n",
    "    second_model_ftrs_trfmd = full_transform.fit_transform(second_model_ftrs_drop)\n",
    "\n",
    "    #transforming the valdation features\n",
    "\n",
    "    first_model_ftrs_trfmd = full_transform.fit_transform(first_model_ftrs)\n",
    "    first_model_val_ftrs_trfmd = full_transform.transform(first_model_val_ftrs)\n",
    "    \n",
    "    second_model_ftrs_trfmd = full_transform.fit_transform(second_model_ftrs_drop)\n",
    "\n",
    "    #First model\n",
    "    hc_predictions_rtree_com = choose_model(m1, first_model_ftrs_trfmd, first_model_lbls, first_model_val_ftrs_trfmd )\n",
    "\n",
    "    #check mse for first model alone\n",
    "    error_mod_comb_first = np.sqrt(mean_squared_error(first_model_val_lbls, hc_predictions_rtree_com))\n",
    "    #print(\"MSE\",error_mod_comb_first)\n",
    "    #obtain a list containing index to non zero predictions for both the training data(using the nb_val) and the validation set, \n",
    "    #using the predictions from the first part\n",
    "    \n",
    "    ftr_list = [] #fltr_list\n",
    "    col_rid = (second_model_val_ftrs.shape[1] - 1)\n",
    "\n",
    "    for i in range(hc_predictions_rtree_com.shape[0]):\n",
    "        if (hc_predictions_rtree_com[i] == 0 ):\n",
    "            ftr_list.append((second_model_val_ftrs.iloc[i,col_rid]) - 1)\n",
    "\n",
    "    scnd_set = second_model_val_ftrs.drop(ftr_list)\n",
    "    \n",
    "    scnd_set_drpd = scnd_set.drop(['Claim_Amount','Row_ind'], axis=1)\n",
    "\n",
    "    #transform the validation features and get the labels\n",
    "    second_model_val_lbls = scnd_set['Claim_Amount']\n",
    "    second_model_val_ftrs_trfmd = full_transform.transform(scnd_set_drpd)\n",
    "    \n",
    "    #second model\n",
    "    #assessing the performance over the validation set\n",
    "   \n",
    "    hc_predictions_linear_com = choose_model(m2, second_model_ftrs_trfmd, second_model_lbls, second_model_val_ftrs_trfmd)\n",
    "    \n",
    "    import numpy as np\n",
    "    total_pred = np.concatenate((hc_predictions_rtree_com, hc_predictions_linear_com))\n",
    "    total_pred.shape\n",
    "    \n",
    "    all_lbls = pd.concat([first_model_val_lbls, second_model_val_lbls])\n",
    "    all_lbls.shape\n",
    "    \n",
    "    #We can now compute the RMSE obtained with this predictive model. We can use the scikit-learn routine for computing the mean squared error and then compute the square root.\n",
    "    #gradient tree regression\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "    error_mod_comb = np.sqrt(mean_squared_error(all_lbls, total_pred))\n",
    "    \n",
    "    \n",
    "    return (error_mod_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comparison of different combinations of models\n",
    "\"\"\"\n",
    "\n",
    "test_set = get_data('./train.csv')\n",
    "t_data = test_set   \n",
    "rel_t_data = prep_data(test_set)\n",
    "balanced_hc_train_set = bal_set(rel_t_data)\n",
    "\n",
    "#fr_lin = comb_models(balanced_hc_train_set, 'Forests', 'Linear' )\n",
    "#gr_lin = comb_models(balanced_hc_train_set, 'Gradient', 'Linear' )\n",
    "#fr_rd = comb_models(balanced_hc_train_set, 'Forests', 'Ridge' )\n",
    "gr_rd = comb_models(balanced_hc_train_set, 'Gradient', 'Ridge' )\n",
    "print(gr_rd) # fr_lin #gr_lin, fr_rd, gr_rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run the best combination of the models\n",
    "\"\"\"\n",
    "\n",
    "def best_predictor(test_data):\n",
    "    test_set = test_data\n",
    "    t_data = test_set   \n",
    "    rel_t_data = prep_data(test_set)\n",
    "    \n",
    "    balanced_hc_train_set = bal_set(rel_t_data)\n",
    "\n",
    "    ttpr = comb_models(balanced_hc_train_set, 'Forests', 'Ridge' )\n",
    "    return (ttpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = get_data('./train.csv')\n",
    "bst_performer = best_predictor(test_set)\n",
    "print(\"Mean Square Error of the Best Performing Model:\",bst_performer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
